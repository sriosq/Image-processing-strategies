{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44965be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef326da",
   "metadata": {},
   "source": [
    "# Loading paths -> Whenever changing of project, it is IMPORTANT to reset the kernel </br>\n",
    "*You dont want to have memory issues or sth like that*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed90ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the base to the datapath\n",
    "path_database_D = \"D:/UNF_data/2024_08_23/test_model_T1w/MP2RAGE/airTissue_output/T1w_MP2RAGE_cervical_20240823134311_21.nii.gz\"\n",
    "path_database_C = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_028/final_test2.nii.gz\"\n",
    "path_img_curr_folder = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/finals/complete_body_plus_trachea_segs.nii.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b21357",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img2 = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/whole_FOV_c1t8/spineseg_from_T1w.nii.gz\"\n",
    "path_img3 = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/finals/grouped_tissue_types.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3240fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x = \"E:/msc_data/sc_qsm/data/wb/data/ratatouille_corrected_pixels.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60155962",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tissue_to_mr = \"C:/Users/User/msc_project/tissue-to-MRproperty/data/cropped_trachea_plus_body.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7a2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fm_comp_chimap = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/fm_comp_mk2/db0_030_wb_chimap.nii.gz\"\n",
    "path_to_fm_comp_init_mask = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/fm_comp_mk2/step1_ROI_masks/db0_030_sim_wb_box_c2_t7.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96abd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 828)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gt_data = nib.load(path_x)  # labels_total_seg.nii.gz\n",
    "image_gt = np.array(image_gt_data.get_fdata())\n",
    "# Always check dimensions of the image\n",
    "image_gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3953809",
   "metadata": {},
   "source": [
    "### Image GT2 & Image GT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecf74ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gt_data2 = nib.load(path_to_fm_comp_chimap)  # \n",
    "image_gt2 = np.array(image_gt_data2.get_fdata())\n",
    "# Always check dimensions of the image\n",
    "image_gt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979beb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gt_data3 = nib.load(path_to_fm_comp_init_mask)  # \n",
    "image_gt3 = np.array(image_gt_data3.get_fdata())\n",
    "# Always check dimensions of the image\n",
    "image_gt3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cbbec",
   "metadata": {},
   "source": [
    "# Using image_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e224e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to edit when working on GT2\n",
    "Size_X=(image_gt.shape)[0]\n",
    "Size_Y=(image_gt.shape)[1]\n",
    "Size_Z=(image_gt.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "bone_list = np.sort(np.arange(26,38))\n",
    "disc_list = np.arange(211,222)\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "\n",
    "            pixel = image_gt[i,j,k]\n",
    "            \n",
    "            if  pixel == 289 or pixel == 324 or pixel == 196:\n",
    "                img_new_LE[i,j,k] = 1\n",
    "\n",
    "\n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data.affine)\n",
    "gt_outpath = \"E:/msc_data/sc_qsm/data/wb/data/canal.nii.gz\"\n",
    "nib.save(new_nifti_img, gt_outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558f8543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When working with segmentations through programs that you dont know the label - id relationship\n",
    "# It is usefull to show how many labels there are.\n",
    "np.unique(image_gt)\n",
    "# Easy way to check which id number are used and avoid overwriting numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542e979",
   "metadata": {},
   "source": [
    "# Using 2 different images to create new custom combination of masks or images </br>\n",
    "Uses image_gt2 and image_gt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006d7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because in theory both images have same dimensions, we can select any of them for the dimensions\n",
    "Size_X=(image_gt2.shape)[0]\n",
    "Size_Y=(image_gt2.shape)[1]\n",
    "Size_Z=(image_gt2.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "            \n",
    "            # For the FM comparison mk2 if the chi map is == 9.055 or 9.05 we must save it as 1 else 0\n",
    "            pixel_chimap = image_gt2[i,j,k] # \n",
    "            pixel_mask = image_gt3[i,j,k] # \n",
    "\n",
    "            if pixel_chimap == -9.05 or pixel_chimap == -9.055 or pixel_chimap == -11:\n",
    "                if pixel_mask == 1:\n",
    "                    img_new_LE[i,j,k] = 1\n",
    "                else:\n",
    "                    img_new_LE[i,j,k] = 0\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data2.affine)\n",
    "nib.save(new_nifti_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/fm_comp_mk2/step_2_tissue_and_bone_masks/db0_030_wb_c2_t7_box_st_bone.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798cb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code when working with gt\n",
    "Size_X=(image_gt.shape)[0]\n",
    "Size_Y=(image_gt.shape)[1]\n",
    "Size_Z=(image_gt.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "bone_list = np.sort(np.arange(23,38))\n",
    "\n",
    "disc_list = np.arange(209,223)\n",
    "\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "\n",
    "            pixel = image_gt[i,j,k]\n",
    "            \n",
    "            if  pixel == 100:\n",
    "                img_new_LE[i,j,k] = 1\n",
    "\n",
    "            else:\n",
    "                img_new_LE[i,j,k] = 0\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data.affine)\n",
    "nib.save(new_nifti_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/spinal_cord_AMU_VC.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of MR labels grouped from total seg MR:\n",
    "\n",
    "water_list = [1,3,4,5,6,7,8,9,14,15,22,23,24,25]\n",
    "muscle_list = [44,45,46]\n",
    "special_air = [10,11,12]\n",
    "\n",
    "# From spine seg, that were merged: \n",
    "bone_list = np.sort(np.arange(26,38))\n",
    "disc_list = np.arange(211,222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a67050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file name choose now\n",
    "out_fn = \"only_sc_gre_spine_seg.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9741cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to force mask to be binarized\n",
    "# This seems to be an issue when working with TotalSegmentator masks\n",
    "Size_X=(image_gt.shape)[0]\n",
    "Size_Y=(image_gt.shape)[1]\n",
    "Size_Z=(image_gt.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(image_gt[:,0,0])):\n",
    "    for j in range( len(image_gt[0,:,0])):\n",
    "        for k in range( len(image_gt[0,0,:])):\n",
    "            if image_gt[i,j,z] > 0.5 :\n",
    "                img_new_LE[i,j,z] = 1\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data.affine)\n",
    "nib.save(new_nifti_img, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5701e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 320)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you can copy and paste the code above and create your own conditions!\n",
    "# Padding code to new dimensions:\n",
    "target_dims = (192,320,320)\n",
    "padded_name = \"padded_gre.nii.gz\"\n",
    "padded_img = np.zeros(target_dims)\n",
    "\n",
    "# Compute the padding offsets to center the original image\n",
    "offset_z = (target_dims[0] - image_gt.shape[0]) // 2\n",
    "offset_y = (target_dims[1] - image_gt.shape[1]) // 2\n",
    "offset_x = (target_dims[2] - image_gt.shape[2]) // 2\n",
    "\n",
    "# Place the first image into the center of the padded array\n",
    "padded_img[offset_z:offset_z + image_gt.shape[0],\n",
    "             offset_y:offset_y + image_gt.shape[1],\n",
    "             offset_x:offset_x + image_gt.shape[2]] = image_gt\n",
    "\n",
    "# Verify dimensions\n",
    "padded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df84141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nifti_img = nib.Nifti1Image(padded_img, image_gt_data.affine)\n",
    "nib.save(new_nifti_img, padded_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e230ff",
   "metadata": {},
   "source": [
    "# Correcting from slicer </br>\n",
    "*Instead of correcting the segmentation file in slicer that have a lot of diferent values, better to group them up frst!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dfb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_list = [1,2,3,4,5,6,7,8,9,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,36,37,38,39,40,41]\n",
    "soft_tissue_list = [10,11]\n",
    "sinus_list = [12,14]\n",
    "trachea = [13,16,17]\n",
    "lungs = [15,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46c73fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_slicer = 'D:/UNF_data/2024_08_23/slicer_work/final_slicer2.nii.gz'\n",
    "slicer_img = nib.load(path_to_slicer)\n",
    "slicer_data = slicer_img.get_fdata()\n",
    "slicer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d369aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code when working with gt\n",
    "Size_X=(slicer_data.shape)[0]\n",
    "Size_Y=(slicer_data.shape)[1]\n",
    "Size_Z=(slicer_data.shape)[2]\n",
    "# New volume\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "\n",
    "# In select tool for compare fm we have that\n",
    "# 7 for lung\n",
    "# 8 for trachea \n",
    "# 2 for fat\n",
    "# 3 for bone\n",
    "# 5 for disc\n",
    "# 10 for organ, 12 for muscle and 256 for spinal cord\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "\n",
    "            pixel = slicer_data[i,j,k]\n",
    "            \n",
    "            if  pixel in bone_list:\n",
    "                img_new_LE[i,j,k] = 3\n",
    "\n",
    "            elif pixel in soft_tissue_list:\n",
    "                img_new_LE[i,j,k] = 2\n",
    "            \n",
    "            elif pixel in sinus_list:\n",
    "                img_new_LE[i,j,k] = 15\n",
    "\n",
    "            # For lungs - internal air\n",
    "            elif pixel in lungs:\n",
    "                img_new_LE[i,j,k] = 7\n",
    "            # For trachea - internal air\n",
    "            elif pixel in trachea:\n",
    "                img_new_LE[i,j,k] = 8\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, slicer_img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7460182",
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.save(new_nifti_img, \"D:/UNF_data/2024_08_23/slicer_work/slicer_to_converter_segs_raw_better.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6f9a7",
   "metadata": {},
   "source": [
    "# <span style=\"color:#D81B60\"> Working grouping samseg labels </span> </br>\n",
    "\n",
    "This depends on the segmentation list offered by FSL - Samseg </br>\n",
    "\n",
    "This must be run on either Linux/MacOS or WSL </br>\n",
    "\n",
    "We just want a fairly decent brain and skull segmentation that we can later on finetune and smoothen out with Slicer :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d994973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 270, 320)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_samseg_segs = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\A1_samseg/db0_035_samseg.nii.gz\"\n",
    "samseg_img = nib.load(path_to_samseg_segs)\n",
    "samseg_data = np.array(samseg_img.get_fdata())\n",
    "samseg_data.shape\n",
    "# Previous shape 301 320 843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3ec42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numbers, this might change with new releases\n",
    "# Last updated for Samseg under freesurfer 8.0.0-beta\n",
    "samseg_brain_list = [2,3,4,5,7,8,10,11,12,13,14,15,16,17,18,24,26,28,30,31,41,42,43,44,46,47,49,50,51,52,53,54,58,60,62,63,72,77,80,85] #16 is the brainstem\n",
    "samseg_skull_list = [165]\n",
    "\n",
    "Size_X=(samseg_data.shape)[0]\n",
    "Size_Y=(samseg_data.shape)[1]\n",
    "Size_Z=(samseg_data.shape)[2]\n",
    "\n",
    "img_new_LE = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(samseg_data[:,0,0])):\n",
    "    for j in range( len(samseg_data[0,:,0])):\n",
    "        for k in range( len(samseg_data[0,0,:])):\n",
    "\n",
    "            pixel = samseg_data[i,j,k]\n",
    "            \n",
    "            if pixel in samseg_brain_list:\n",
    "                img_new_LE[i,j,k] = 23\n",
    "            if pixel in samseg_skull_list:\n",
    "                img_new_LE[i,j,k] = 25\n",
    "\n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, samseg_img.affine)\n",
    "out_path = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\A1_samseg/grouped_db0_035_samseg.nii.gz\"\n",
    "nib.save(new_nifti_img, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcabe1",
   "metadata": {},
   "source": [
    "### Now to add the skull and brain segmentations after correction of the skull - smoothing </br>\n",
    "After grouping samseg labels of the brain, we need to smooth the labels in order to create realistic brain and skull segmentations! </br>\n",
    "Export to a binary map will change the value of the labels automatically but then we can load them here and change to their appropriate number!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246a1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to load the new segs and the segmentation file where we want to add it\n",
    "smooth_samsegs_img = nib.load(\"E:/msc_data/ismrm_2025/dB0_033_dup1/anat/t1w/segmentations/A1_samseg/smooth_grouped_samseg.nii.gz\")\n",
    "smooth_samsegs_data = np.array(smooth_samsegs_img.get_fdata())\n",
    "# Add the AirSoft-net results to the brain FOV\n",
    "segmentations_to_add_img = nib.load(\"E:/msc_data/ismrm_2025/dB0_033_dup1/anat/t1w/segmentations/A3_airsoftnet/brain/T1w_MP2RAGE_brain_20250124141243_10.nii.gz\")\n",
    "segmentations_to_add_data = np.array(segmentations_to_add_img.get_fdata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0095398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know that they are in the same coordinates we can use same index\n",
    "Size_X=(smooth_samsegs_data.shape)[0]\n",
    "Size_Y=(smooth_samsegs_data.shape)[1]\n",
    "Size_Z=(smooth_samsegs_data.shape)[2]\n",
    "\n",
    "new_segmentation_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(segmentations_to_add_data[:,0,0])):\n",
    "    for j in range( len(segmentations_to_add_data[0,:,0])):\n",
    "        for k in range( len(segmentations_to_add_data[0,0,:])):\n",
    "\n",
    "            pixel_samseg = smooth_samsegs_data[i,j,k]\n",
    "            pixel_airsoft_net = segmentations_to_add_data[i,j,k]\n",
    "\n",
    "            if pixel_samseg == 1 and pixel_airsoft_net == 1: \n",
    "                # This that we are in the brain therefore newseg = 23\n",
    "\n",
    "                    new_segmentation_data[i,j,k] = 23\n",
    "            elif pixel_airsoft_net == 1 and pixel_samseg == 2: # This is the skull \n",
    "\n",
    "                new_segmentation_data[i,j,k] = 25\n",
    "\n",
    "            elif pixel_airsoft_net == 2 or pixel_airsoft_net == 3:\n",
    "\n",
    "                new_segmentation_data[i,j,k] = 15 # Sinuses and ear canal\n",
    "\n",
    "            elif pixel_airsoft_net == 4: # Trachea\n",
    "\n",
    "                new_segmentation_data[i,j,k] = 8\n",
    "\n",
    "            elif pixel_airsoft_net == 5 or pixel_airsoft_net == 6: # Lungs\n",
    "                \n",
    "                new_segmentation_data[i,j,k] = 7\n",
    "\n",
    "            else:\n",
    "                new_segmentation_data[i,j,k] = pixel_airsoft_net\n",
    "\n",
    "new_seg_img = nib.Nifti1Image(new_segmentation_data, segmentations_to_add_img.affine)\n",
    "outpath_smooth_brain_FOV = \"E:/msc_data/ismrm_2025/dB0_033_dup1/anat/t1w/segmentations/merging_outputs/complete_brain_FOV_segs.nii.gz\"\n",
    "nib.save(new_seg_img, outpath_smooth_brain_FOV)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24992058",
   "metadata": {},
   "source": [
    "### Converting samseg labelmap to tissue to MR converter dicitonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68180f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samseg_img = nib.load(\"C:/Users/User/msc_project/sus-optimization/data/crop_ismrm/final_smooth_wb_db0_030_slicer_output.nii.gz\")\n",
    "final_samseg_data = final_samseg_img.get_fdata()\n",
    "\n",
    "Size_X=(final_samseg_data.shape)[0]\n",
    "Size_Y=(final_samseg_data.shape)[1]\n",
    "Size_Z=(final_samseg_data.shape)[2]\n",
    "\n",
    "final_segmentations_converter = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(final_samseg_data[:,0,0])):\n",
    "    for j in range( len(final_samseg_data[0,:,0])):\n",
    "        for k in range( len(final_samseg_data[0,0,:])):\n",
    "\n",
    "            pixel = final_samseg_data[i,j,k]\n",
    "            final_pixel = final_segmentations_converter[i,j,k]\n",
    "\n",
    "            if pixel == 1: # Fat label\n",
    "                final_segmentations_converter[i,j,k] = 2\n",
    "            if pixel == 2 or pixel == 6: # Bone from spine and skull respectively\n",
    "                final_segmentations_converter[i,j,k] = 3\n",
    "            if pixel == 3: # Lungs\n",
    "                final_segmentations_converter[i,j,k] = 7\n",
    "            if pixel == 4: # Sinus\n",
    "                final_segmentations_converter[i,j,k] = 15\n",
    "            if pixel == 5: # Brain\n",
    "                final_segmentations_converter[i,j,k] = 23\n",
    "            if pixel == 7: # Trachea\n",
    "                final_segmentations_converter[i,j,k] = 8\n",
    "\n",
    "final_segmentations_converter_img =  nib.Nifti1Image(final_segmentations_converter, final_samseg_img.affine)\n",
    "nib.save(final_segmentations_converter_img, \"C:/Users/User/msc_project/sus-optimization/data/crop_ismrm/final_smooth_wb_db0_030_segs.nii.gz\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ac8ec",
   "metadata": {},
   "source": [
    "# <span style=\"color:#47974A\"> Converting SpineSeg merged to tissue types </span> </br>\n",
    "\n",
    "This is a merger code for all the labels from: https://github.com/neuropoly/totalspineseg </br>\n",
    "\n",
    "The list used for merging will depend on their class list or any updates - check before running </br>\n",
    "\n",
    "This are created to be used in the final merger hence, to avoid conflict of labels they start at 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77aef83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The order is depending on the order of each label file,\n",
    "# If in theory they would be sorted, this could be a bit more automated\n",
    "# But the lists will change unless we come up with a way to automate it\n",
    "\n",
    "#spinal_cord_list = [1,2] # Cord and Canal\n",
    "bones = [3,4,5,6,7,17,18,19,20,21,22,23,24,25,35,36,37,38,39,40,41,42,43,44]\n",
    "cartilage = [8,9,10,11,12,26,27,28,29,30,31,32,33,34,45,46,47,48,49,50,51,52,53]\n",
    "\n",
    "spinal_structures = [1, 2]\n",
    "\n",
    "# List for all bones of the spine\n",
    "vertebrae = [\n",
    "    11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, \n",
    "    31, 32, 41, 42, 43, 44, 45, 50\n",
    "]\n",
    "\n",
    "# List for all the intervertebral discs\n",
    "discs = [\n",
    "    63, 64, 65, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, \n",
    "    91, 92, 93, 94, 95, 100\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee25952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 270, 818)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_spineseg = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\D3_spineseg\\spineseg_wb_step2_output.nii.gz\"\n",
    "spineseg_og_img = nib.load(path_to_spineseg)\n",
    "spineseg_og_data = spineseg_og_img.get_fdata()\n",
    "spineseg_og_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814475e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(spineseg_og_data.shape)[0]\n",
    "Size_Y=(spineseg_og_data.shape)[1]\n",
    "Size_Z=(spineseg_og_data.shape)[2]\n",
    "\n",
    "spine_seg_grouped = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(spineseg_og_data[:,0,0])):\n",
    "    for j in range( len(spineseg_og_data[0,:,0])):\n",
    "        for k in range( len(spineseg_og_data[0,0,:])):\n",
    "\n",
    "            pixel = spineseg_og_data[i,j,k]\n",
    "\n",
    "            if pixel in spinal_structures: \n",
    "                spine_seg_grouped[i,j,k] = 10 # Spinal cord\n",
    "\n",
    "            if pixel in vertebrae: \n",
    "                spine_seg_grouped[i,j,k]  = 11 # Bones\n",
    "\n",
    "            if pixel in discs: \n",
    "                spine_seg_grouped[i,j,k]  = 12 # Discs\n",
    "            \n",
    "\n",
    "grouped_spineseg_img = nib.Nifti1Image(spine_seg_grouped, spineseg_og_img.affine)\n",
    "\n",
    "path_to_spineseg_merged_output = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\D3_spineseg/converted_merged_spineseg.nii.gz\"\n",
    "\n",
    "nib.save(grouped_spineseg_img, path_to_spineseg_merged_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ae9be",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\"> Convert final wholebody segmentations Slicer to Tissue to MR dictionaries </br>\n",
    "\n",
    "Now, the problem we have with Slicer Segmentations is that they don't carry the label values when we create a volume from it. </br>\n",
    "\n",
    "So this if statements depend on the order of your labels, if you separate them properly as inidicated in previous sub-grouped codes you might have the same or even similar </br>\n",
    "\n",
    "If not, just edit, keep a close look at the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e34b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 270, 818)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_correct_segmentations = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\merging_outputs/corrected_wb_segs.nii.gz\"\n",
    "pre_wholebody_segmentations_img = nib.load(path_to_correct_segmentations)\n",
    "pre_wholebody_segmentations_data = pre_wholebody_segmentations_img.get_fdata()\n",
    "pre_wholebody_segmentations_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4be9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(pre_wholebody_segmentations_data.shape)[0]\n",
    "Size_Y=(pre_wholebody_segmentations_data.shape)[1]\n",
    "Size_Z=(pre_wholebody_segmentations_data.shape)[2]\n",
    "\n",
    "grouped_wholebody_segs = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(pre_wholebody_segmentations_data[:,0,0])):\n",
    "    for j in range( len(pre_wholebody_segmentations_data[0,:,0])):\n",
    "        for k in range( len(pre_wholebody_segmentations_data[0,0,:])):\n",
    "\n",
    "            pixel = pre_wholebody_segmentations_data[i,j,k]\n",
    "\n",
    "            if pixel == 10:\n",
    "                grouped_wholebody_segs[i,j,k] = 2 # Fat/Body\n",
    "\n",
    "            if pixel == 2:\n",
    "                grouped_wholebody_segs[i,j,k] = 15 # Ear canal and sinuses\n",
    "\n",
    "            if pixel == 1 :\n",
    "                grouped_wholebody_segs[i,j,k] = 8 # Trachea\n",
    "\n",
    "            if pixel == 4 or pixel == 5:\n",
    "                grouped_wholebody_segs[i,j,k] = 7 # Lungs\n",
    "\n",
    "            if pixel == 3:\n",
    "                grouped_wholebody_segs[i,j,k] = 23 # Brain\n",
    "\n",
    "            if pixel == 6:\n",
    "                grouped_wholebody_segs[i,j,k] = 25 # Skull\n",
    "\n",
    "            if pixel == 7:\n",
    "                grouped_wholebody_segs[i,j,k] = 3 # Bone from spine\n",
    "\n",
    "            if pixel == 8:\n",
    "                grouped_wholebody_segs[i,j,k] = 5 # Intervertebral disc\n",
    "\n",
    "            if pixel == 9:\n",
    "                grouped_wholebody_segs[i,j,k] = 256 # Spinal cord\n",
    "\n",
    "            #if pixel == 14:\n",
    "            #    grouped_wholebody_segs[i,j,k] = 289 # SC CSF\n",
    "\n",
    "\n",
    "\n",
    "grouped_wb_segs_img = nib.Nifti1Image(grouped_wholebody_segs, pre_wholebody_segmentations_img.affine)\n",
    "\n",
    "path_to_final_merged_segmentations = \"E:/msc_data/ismrm_2025/dB0_033_dup1/anat/t1w/segmentations/merging_outputs/final_merged_wb_segs.nii.gz\"\n",
    "\n",
    "nib.save(grouped_wb_segs_img, path_to_final_merged_segmentations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fde45d",
   "metadata": {},
   "source": [
    "### In case you need to change the pixel number use this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ee642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(pre_wholebody_segmentations_data.shape)[0]\n",
    "Size_Y=(pre_wholebody_segmentations_data.shape)[1]\n",
    "Size_Z=(pre_wholebody_segmentations_data.shape)[2]\n",
    "\n",
    "grouped_wholebody_segs = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(pre_wholebody_segmentations_data[:,0,0])):\n",
    "    for j in range( len(pre_wholebody_segmentations_data[0,:,0])):\n",
    "        for k in range( len(pre_wholebody_segmentations_data[0,0,:])):\n",
    "\n",
    "            pixel = pre_wholebody_segmentations_data[i,j,k]\n",
    "\n",
    "            if pixel == 7:\n",
    "                grouped_wholebody_segs[i,j,k] = 2 # Fat/Body\n",
    "\n",
    "            if pixel == 6 or pixel == 8:\n",
    "                grouped_wholebody_segs[i,j,k] = 15 # Ear canal and sinuses\n",
    "\n",
    "            if pixel == 9 :\n",
    "                grouped_wholebody_segs[i,j,k] = 8 # Trachea\n",
    "\n",
    "            if pixel == 10 or pixel == 11:\n",
    "                grouped_wholebody_segs[i,j,k] = 7 # Lungs\n",
    "\n",
    "            if pixel == 4:\n",
    "                grouped_wholebody_segs[i,j,k] = 23 # Brain\n",
    "\n",
    "            if pixel == 5:\n",
    "                grouped_wholebody_segs[i,j,k] = 25 # Skull\n",
    "\n",
    "            if pixel == 2:\n",
    "                grouped_wholebody_segs[i,j,k] = 3 # Bone from spine\n",
    "\n",
    "            if pixel == 3:\n",
    "                grouped_wholebody_segs[i,j,k] = 5 # Intervertebral disc\n",
    "\n",
    "            if pixel == 1:\n",
    "                grouped_wholebody_segs[i,j,k] = 256 # Spinal cord\n",
    "\n",
    "            #if pixel == 14:\n",
    "            #    grouped_wholebody_segs[i,j,k] = 289 # SC CSF\n",
    "\n",
    "\n",
    "\n",
    "grouped_wb_segs_img = nib.Nifti1Image(grouped_wholebody_segs, pre_wholebody_segmentations_img.affine)\n",
    "\n",
    "path_to_final_merged_segmentations = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\merging_outputs/final_merged_wb_segs.nii.gz\"\n",
    "\n",
    "nib.save(grouped_wb_segs_img, path_to_final_merged_segmentations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2171a06",
   "metadata": {},
   "source": [
    "## Corrected whole-body CT phantom to only Spinal Cord </br>\n",
    "Surrounded only by sc_csf and therefore after convolution with dipole kernel it would be a ground truth for BGFR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7825c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_89132\\2538068053.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  corrected_pixels_wb_img = nib.load(\"E:\\msc_data\\sc_qsm\\data\\wb\\data/ratatouille_corrected_pixels.nii.gz\")\n"
     ]
    }
   ],
   "source": [
    "corrected_pixels_wb_img = nib.load(\"E:\\msc_data\\sc_qsm\\data\\wb\\data/ratatouille_corrected_pixels.nii.gz\")\n",
    "corrected_pixels_wb_data = corrected_pixels_wb_img.get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd9e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(corrected_pixels_wb_data.shape)[0]\n",
    "Size_Y=(corrected_pixels_wb_data.shape)[1]\n",
    "Size_Z=(corrected_pixels_wb_data.shape)[2]\n",
    "\n",
    "bgfr_validation_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(corrected_pixels_wb_data[:,0,0])):\n",
    "    for j in range( len(corrected_pixels_wb_data[0,:,0])):\n",
    "        for k in range( len(corrected_pixels_wb_data[0,0,:])):\n",
    "            pixel = corrected_pixels_wb_data[i,j,k]\n",
    "            # Create the chi distribution now faster\n",
    "            if pixel == 324: # Gray Matter\n",
    "                bgfr_validation_data[i,j,k] = -9.030\n",
    "            elif pixel == 196: # White Matter\n",
    "                bgfr_validation_data[i,j,k] = -9.083 \n",
    "            else:\n",
    "                # Everything outside should be CSF:\n",
    "                bgfr_validation_data[i,j,k] = -9.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86d02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_csf_mask = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(corrected_pixels_wb_data[:,0,0])):\n",
    "    for j in range( len(corrected_pixels_wb_data[0,:,0])):\n",
    "        for k in range( len(corrected_pixels_wb_data[0,0,:])):\n",
    "            pixel = corrected_pixels_wb_data[i,j,k]\n",
    "            # Create the chi distribution now faster\n",
    "            if pixel == 289: # Spinal Cord csf\n",
    "                sc_csf_mask[i,j,k] = 1\n",
    "\n",
    "sc_csf_img = nib.Nifti1Image(sc_csf_mask, corrected_pixels_wb_img.affine)\n",
    "nib.save(sc_csf_img,\"E:/msc_data/sc_qsm/data/wb/masks/sc_csf.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc254fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgfr_validation_img = nib.Nifti1Image(bgfr_validation_data, corrected_pixels_wb_img.affine)\n",
    "nib.save(bgfr_validation_img,\"E:/msc_data/sc_qsm/data/wb/data/bgfr_chidist.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d904b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(corrected_pixels_wb_data.shape)[0]\n",
    "Size_Y=(corrected_pixels_wb_data.shape)[1]\n",
    "Size_Z=(corrected_pixels_wb_data.shape)[2]\n",
    "\n",
    "detail_sc_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(corrected_pixels_wb_data[:,0,0])):\n",
    "    for j in range( len(corrected_pixels_wb_data[0,:,0])):\n",
    "        for k in range( len(corrected_pixels_wb_data[0,0,:])):\n",
    "            pixel = corrected_pixels_wb_data[i,j,k]\n",
    "            # Create the chi distribution now faster\n",
    "            if pixel == 324: # Gray Matter\n",
    "                detail_sc_data[i,j,k] = 1\n",
    "            elif pixel == 196: # White Matter\n",
    "                detail_sc_data[i,j,k] = 2 \n",
    "            else:\n",
    "                # Everything outside should be CSF:\n",
    "                detail_sc_data[i,j,k] = 3\n",
    "                \n",
    "detail_sc_img = nib.Nifti1Image(detail_sc_data, corrected_pixels_wb_img.affine)\n",
    "nib.save(detail_sc_img,\"E:/msc_data/sc_qsm/data/wb/data/detailed_sc_mask.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5614bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(corrected_pixels_wb_data.shape)[0]\n",
    "Size_Y=(corrected_pixels_wb_data.shape)[1]\n",
    "Size_Z=(corrected_pixels_wb_data.shape)[2]\n",
    "\n",
    "gm_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(corrected_pixels_wb_data[:,0,0])):\n",
    "    for j in range( len(corrected_pixels_wb_data[0,:,0])):\n",
    "        for k in range( len(corrected_pixels_wb_data[0,0,:])):\n",
    "            pixel = corrected_pixels_wb_data[i,j,k]\n",
    "            # Create the chi distribution now faster\n",
    "            if pixel == 324: # Gray Matter\n",
    "                gm_data[i,j,k] = 1\n",
    "            else:\n",
    "                gm_data[i,j,k] = 0\n",
    "\n",
    "gm_img = nib.Nifti1Image(gm_data, corrected_pixels_wb_img.affine)\n",
    "nib.save(gm_img,\"E:/msc_data/sc_qsm/data/wb/data/gm_mask.nii.gz\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0584823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(corrected_pixels_wb_data.shape)[0]\n",
    "Size_Y=(corrected_pixels_wb_data.shape)[1]\n",
    "Size_Z=(corrected_pixels_wb_data.shape)[2]\n",
    "\n",
    "wm_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(corrected_pixels_wb_data[:,0,0])):\n",
    "    for j in range( len(corrected_pixels_wb_data[0,:,0])):\n",
    "        for k in range( len(corrected_pixels_wb_data[0,0,:])):\n",
    "            pixel = corrected_pixels_wb_data[i,j,k]\n",
    "            # Create the chi distribution now faster\n",
    "            if pixel == 196: # Gray Matter\n",
    "                wm_data[i,j,k] = 1\n",
    "            else:\n",
    "                wm_data[i,j,k] = 0\n",
    "\n",
    "wm_img = nib.Nifti1Image(wm_data, corrected_pixels_wb_img.affine)\n",
    "nib.save(wm_img,\"E:/msc_data/sc_qsm/data/wb/data/wm_mask.nii.gz\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447db88",
   "metadata": {},
   "source": [
    "# Spine Seg of T1w/GRE Magnitude -> Only SC for demod and labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5c4c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 270, 818)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E:/msc_data/ismrm_2025/db0_032/anat/t1w/segmentations/D3_spineseg\n",
    "# E:/msc_data/ismrm_2025/db0_031/fm/dmod_meas/insp/segmentation_files/spineseg\n",
    "spineseg_mask_img = nib.load(r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\\D3_spineseg\\spineseg_wb_step2_output.nii.gz\")\n",
    "out_folder_path = r\"E:\\msc_data\\ismrm_2025\\dB0_035\\anat\\t1w\\segmentations\"\n",
    "spineseg_mask_data = spineseg_mask_img.get_fdata()\n",
    "spineseg_mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec67185",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(spineseg_mask_data.shape)[0]\n",
    "Size_Y=(spineseg_mask_data.shape)[1]\n",
    "Size_Z=(spineseg_mask_data.shape)[2]\n",
    "\n",
    "onlysc_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "# According to the documentation only labels 1 and 2 are the cord and canal\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "            \n",
    "            pixel = spineseg_mask_data[i,j,k]\n",
    "\n",
    "            if pixel == 1 :\n",
    "                onlysc_data[i,j,k] = 1\n",
    "            \n",
    "onlysc_img = nib.Nifti1Image(onlysc_data, spineseg_mask_img.affine)\n",
    "outfile = os.path.join(out_folder_path, \"cord_mask.nii.gz\")\n",
    "nib.save(onlysc_img,outfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fdae829",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(spineseg_mask_data.shape)[0]\n",
    "Size_Y=(spineseg_mask_data.shape)[1]\n",
    "Size_Z=(spineseg_mask_data.shape)[2]\n",
    "\n",
    "onlysc_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "# According to the documentation only labels 1 and 2 are the cord and canal\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "            \n",
    "            pixel = spineseg_mask_data[i,j,k]\n",
    "\n",
    "            if pixel == 1 or pixel == 2:\n",
    "                onlysc_data[i,j,k] = 1\n",
    "            \n",
    "onlysc_img = nib.Nifti1Image(onlysc_data, spineseg_mask_img.affine)\n",
    "outfile = os.path.join(out_folder_path,\"canal_mask.nii.gz\")\n",
    "nib.save(onlysc_img,outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081f564",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2FA6DC\"> Wholebody CT manipulation </br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f23c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 828)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the spinal cord, wm and gm masks from the whole body SC phantom.\n",
    "ratatouille_img = nib.load(r\"E:\\msc_data\\sc_qsm\\Healthy_WB_CT/ratatouille_corrected_pixels.nii.gz\")\n",
    "out_folder_path = r\"E:\\msc_data\\sc_qsm\\data\\final_masks\"\n",
    "ratatouille_data = ratatouille_img.get_fdata()\n",
    "ratatouille_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86285d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_X=(ratatouille_data.shape)[0]\n",
    "Size_Y=(ratatouille_data.shape)[1]\n",
    "Size_Z=(ratatouille_data.shape)[2]\n",
    "\n",
    "ratatouille_sc_mask = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "# According to the documentation only labels 1 and 2 are the cord and canal\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "            \n",
    "            pixel = ratatouille_data[i,j,k]\n",
    "            # We need to pick the labels that correspond to the white matter\n",
    "            #if pixel == 289 or pixel == 196 or pixel == 324  :\n",
    "                #ratatouille_sc_mask[i,j,k] = 1\n",
    "            # If we only want gray matter:\n",
    "            if pixel == 196:\n",
    "                ratatouille_sc_mask[i,j,k] = 1\n",
    "            # If we only want white matter:\n",
    "            #if pixel == 324  :\n",
    "                #ratatouille_sc_mask[i,j,k] = 1\n",
    "            \n",
    "onlysc_img = nib.Nifti1Image(ratatouille_sc_mask, ratatouille_img.affine)\n",
    "outfile = os.path.join(out_folder_path, \"gray_matter.nii.gz\")\n",
    "nib.save(onlysc_img, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0b766",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9d6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This to force a value to be the only one\n",
    "# This happens when we multiply by a negative value with sct\n",
    "\n",
    "value = 324\n",
    "\n",
    "Size_X=(image_gt2.shape)[0]\n",
    "Size_Y=(image_gt2.shape)[1]\n",
    "Size_Z=(image_gt2.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(image_gt2[:,0,0])):\n",
    "    for j in range( len(image_gt2[0,:,0])):\n",
    "        for z in range( len(image_gt2[0,0,:])):\n",
    "            if image_gt2[i,j,z] == 200 or image_gt2[i,j,z] == 201:\n",
    "                img_new_LE[i,j,z] = 1\n",
    "            else:\n",
    "              img_new_LE[i,j,z] = 0\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, samseg_img.affine)\n",
    "nib.save(new_nifti_img, \"D:/UNF_data/2024_08_23/test_model_T1w/MP2RAGE/spine_output/only_sc_t1w.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e4e72",
   "metadata": {},
   "source": [
    "*Special thank you to fellow Peruvian, researcher and friend N. Medina - Aix Marseille*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa1332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes when tresholding the initial anatomical image, the binarized has wholes on the body of the image.\n",
    "# So we need some way to fill this wholes automatically.\n",
    "\n",
    "def get_neighbors(volume, x, y, z):\n",
    "    neighbors = []\n",
    "    for i in range(-1, 2):\n",
    "        for j in range(-1, 2):\n",
    "            for k in range(-1, 2):\n",
    "                if i == 0 and j == 0 and k == 0:\n",
    "                    continue\n",
    "                xi, yj, zk = x + i, y + j, z + k\n",
    "                if 0 <= xi < volume.shape[0] and 0 <= yj < volume.shape[1] and 0 <= zk < volume.shape[2]:\n",
    "                    neighbors.append(volume[xi, yj, zk])\n",
    "    return neighbors\n",
    "\n",
    "def fill_holes(volume):\n",
    "    filled_volume = volume.copy()\n",
    "    for x in range(volume.shape[0]):\n",
    "        for y in range(volume.shape[1]):\n",
    "            for z in range(volume.shape[2]):\n",
    "                if volume[x, y, z] == 0:  # Assuming 0 is the \"hole\"\n",
    "                    neighbors = get_neighbors(volume, x, y, z)\n",
    "                    if sum(neighbors) > len(neighbors) // 2:  # Majority vote\n",
    "                        filled_volume[x, y, z] = 1\n",
    "    return filled_volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78be2c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 320, 320)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image to load and fill holes\n",
    "path_database = \"correc_thoracic_db0_028.nii.gz\"\n",
    "\n",
    "wholes_image = nib.load(path_database)  # labels_total_seg.nii.gz\n",
    "wholes_data = np.array(image_gt_data.get_fdata())\n",
    "wholes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8002163",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_vol = fill_holes(wholes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7439594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and checking if the wholes were filled correctly\n",
    "fn = \"filled_wholes\"\n",
    "file = \"thoracic_db0_028\"\n",
    "\n",
    "out_fn2 = fn + \"_\" + file + \".nii.gz\"\n",
    "filled_vol_nii = nib.Nifti1Image(filled_vol, affine = wholes_image.affine)\n",
    "nib.save(filled_vol_nii, out_fn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94478758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the labels from Total Segmentator to leave and empty space on the place of the mask\n",
    "\n",
    "# Load the segmentations\n",
    "\n",
    "segmentation_path = \"D:/UNF_data/07_08_2024/T1w/thoracic_volume/thoracic_labels_bin.nii.gz\"\n",
    "\n",
    "segms = nib.load(segmentation_path)\n",
    "segmentation_data = segms.get_fdata()\n",
    "\n",
    "dimensions = np.array(segmentation_data.shape)\n",
    "\n",
    "final_filled_vol = filled_vol.copy()\n",
    "for i in range(dimensions[0]):\n",
    "    for j in range(dimensions[1]):\n",
    "        for k in range(dimensions[2]):\n",
    "            pixel = segmentation_data[i,j,k]\n",
    "            if pixel == 1:\n",
    "                final_filled_vol[i,j,k] = 0\n",
    "\n",
    "out_fn3 = \"final_\" + fn + \"_\" + file + \".nii.gz\"\n",
    "\n",
    "final_nii = nib.Nifti1Image(final_filled_vol, affine = segms.affine)\n",
    "nib.save(final_nii, out_fn3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
