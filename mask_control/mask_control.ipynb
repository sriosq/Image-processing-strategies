{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44965be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef326da",
   "metadata": {},
   "source": [
    "# Loading paths -> Whenever changing of project, it is IMPORTANT to reset the kernel </br>\n",
    "*You dont want to have memory issues or sth like that*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed90ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the base to the datapath\n",
    "path_database_D = \"D:/UNF_data/2024_08_23/test_model_T1w/MP2RAGE/airTissue_output/T1w_MP2RAGE_cervical_20240823134311_21.nii.gz\"\n",
    "path_database_C = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_028/final_test2.nii.gz\"\n",
    "path_img_curr_folder = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/finals/complete_body_plus_trachea_segs.nii.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b21357",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img2 = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/whole_FOV_c1t8/spineseg_from_T1w.nii.gz\"\n",
    "path_img3 = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/finals/grouped_tissue_types.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3240fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/sub-amuVC_T1w_label-all.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60155962",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tissue_to_mr = \"C:/Users/User/msc_project/tissue-to-MRproperty/data/cropped_trachea_plus_body.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7a2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fm_comp_chimap = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/fm_comp_mk2/db0_030_wb_chimap.nii.gz\"\n",
    "path_to_fm_comp_init_mask = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/fm_comp_mk2/step1_ROI_masks/db0_030_sim_wb_box_c2_t7.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d994973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_samseg_segs = \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/samseg_brain_seg.nii.gz\"\n",
    "samseg_img = nib.load(path_to_samseg_segs)\n",
    "samseg_data = np.array(samseg_img.get_fdata())\n",
    "samseg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96abd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gt_data = nib.load(path_x)  # labels_total_seg.nii.gz\n",
    "image_gt = np.array(image_gt_data.get_fdata())\n",
    "# Always check dimensions of the image\n",
    "image_gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3953809",
   "metadata": {},
   "source": [
    "### Image GT2 & Image GT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecf74ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gt_data2 = nib.load(path_to_fm_comp_chimap)  # \n",
    "image_gt2 = np.array(image_gt_data2.get_fdata())\n",
    "# Always check dimensions of the image\n",
    "image_gt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979beb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gt_data3 = nib.load(path_to_fm_comp_init_mask)  # \n",
    "image_gt3 = np.array(image_gt_data3.get_fdata())\n",
    "# Always check dimensions of the image\n",
    "image_gt3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cbbec",
   "metadata": {},
   "source": [
    "# Using image_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e224e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to edit when working on GT2\n",
    "Size_X=(image_gt2.shape)[0]\n",
    "Size_Y=(image_gt2.shape)[1]\n",
    "Size_Z=(image_gt2.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "bone_list = np.sort(np.arange(26,38))\n",
    "disc_list = np.arange(211,222)\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "\n",
    "            pixel = image_gt2[i,j,k]\n",
    "            \n",
    "            if  pixel == 15 :\n",
    "                img_new_LE[i,j,k] = 12\n",
    "            else:\n",
    "                img_new_LE[i,j,k] = pixel\n",
    "\n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data2.affine)\n",
    "nib.save(new_nifti_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/finals/corrected_body_plus_trachea.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558f8543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When working with segmentations through programs that you dont know the label - id relationship\n",
    "# It is usefull to show how many labels there are.\n",
    "np.unique(image_gt)\n",
    "# Easy way to check which id number are used and avoid overwriting numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542e979",
   "metadata": {},
   "source": [
    "# Using 2 different images to create new custom combination of masks or images </br>\n",
    "Uses image_gt2 and image_gt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006d7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because in theory both images have same dimensions, we can select any of them for the dimensions\n",
    "Size_X=(image_gt2.shape)[0]\n",
    "Size_Y=(image_gt2.shape)[1]\n",
    "Size_Z=(image_gt2.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "            \n",
    "            # For the FM comparison mk2 if the chi map is == 9.055 or 9.05 we must save it as 1 else 0\n",
    "            pixel_chimap = image_gt2[i,j,k] # \n",
    "            pixel_mask = image_gt3[i,j,k] # \n",
    "\n",
    "            if pixel_chimap == -9.05 or pixel_chimap == -9.055 or pixel_chimap == -11:\n",
    "                if pixel_mask == 1:\n",
    "                    img_new_LE[i,j,k] = 1\n",
    "                else:\n",
    "                    img_new_LE[i,j,k] = 0\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data2.affine)\n",
    "nib.save(new_nifti_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/fm_comp_mk2/step_2_tissue_and_bone_masks/db0_030_wb_c2_t7_box_st_bone.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798cb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code when working with gt\n",
    "Size_X=(image_gt.shape)[0]\n",
    "Size_Y=(image_gt.shape)[1]\n",
    "Size_Z=(image_gt.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "bone_list = np.sort(np.arange(23,38))\n",
    "\n",
    "disc_list = np.arange(209,223)\n",
    "\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "\n",
    "            pixel = image_gt[i,j,k]\n",
    "            \n",
    "            if  pixel == 100:\n",
    "                img_new_LE[i,j,k] = 1\n",
    "\n",
    "            else:\n",
    "                img_new_LE[i,j,k] = 0\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data.affine)\n",
    "nib.save(new_nifti_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/spinal_cord_AMU_VC.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of MR labels grouped from total seg MR:\n",
    "\n",
    "water_list = [1,3,4,5,6,7,8,9,14,15,22,23,24,25]\n",
    "muscle_list = [44,45,46]\n",
    "special_air = [10,11,12]\n",
    "\n",
    "# From spine seg, that were merged: \n",
    "bone_list = np.sort(np.arange(26,38))\n",
    "disc_list = np.arange(211,222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a67050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file name choose now\n",
    "out_fn = \"only_sc_gre_spine_seg.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9741cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to force mask to be binarized\n",
    "# This seems to be an issue when working with TotalSegmentator masks\n",
    "Size_X=(image_gt.shape)[0]\n",
    "Size_Y=(image_gt.shape)[1]\n",
    "Size_Z=(image_gt.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(image_gt[:,0,0])):\n",
    "    for j in range( len(image_gt[0,:,0])):\n",
    "        for k in range( len(image_gt[0,0,:])):\n",
    "            if image_gt[i,j,z] > 0.5 :\n",
    "                img_new_LE[i,j,z] = 1\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, image_gt_data.affine)\n",
    "nib.save(new_nifti_img, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5701e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 320)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you can copy and paste the code above and create your own conditions!\n",
    "# Padding code to new dimensions:\n",
    "target_dims = (192,320,320)\n",
    "padded_name = \"padded_gre.nii.gz\"\n",
    "padded_img = np.zeros(target_dims)\n",
    "\n",
    "# Compute the padding offsets to center the original image\n",
    "offset_z = (target_dims[0] - image_gt.shape[0]) // 2\n",
    "offset_y = (target_dims[1] - image_gt.shape[1]) // 2\n",
    "offset_x = (target_dims[2] - image_gt.shape[2]) // 2\n",
    "\n",
    "# Place the first image into the center of the padded array\n",
    "padded_img[offset_z:offset_z + image_gt.shape[0],\n",
    "             offset_y:offset_y + image_gt.shape[1],\n",
    "             offset_x:offset_x + image_gt.shape[2]] = image_gt\n",
    "\n",
    "# Verify dimensions\n",
    "padded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df84141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nifti_img = nib.Nifti1Image(padded_img, image_gt_data.affine)\n",
    "nib.save(new_nifti_img, padded_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e230ff",
   "metadata": {},
   "source": [
    "# Correcting from slicer </br>\n",
    "*Instead of correcting the segmentation file in slice that have a lot of diferent values, better to group them up frst!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dfb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_list = [1,2,3,4,5,6,7,8,9,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,36,37,38,39,40,41]\n",
    "soft_tissue_list = [10,11]\n",
    "sinus_list = [12,14]\n",
    "trachea = [13,16,17]\n",
    "lungs = [15,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46c73fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 320, 841)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_slicer = 'D:/UNF_data/2024_08_23/slicer_work/final_slicer2.nii.gz'\n",
    "slicer_img = nib.load(path_to_slicer)\n",
    "slicer_data = slicer_img.get_fdata()\n",
    "slicer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d369aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code when working with gt\n",
    "Size_X=(slicer_data.shape)[0]\n",
    "Size_Y=(slicer_data.shape)[1]\n",
    "Size_Z=(slicer_data.shape)[2]\n",
    "# New volume\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "\n",
    "# In select tool for compare fm we have that\n",
    "# 7 for lung\n",
    "# 8 for trachea \n",
    "# 2 for fat\n",
    "# 3 for bone\n",
    "# 5 for disc\n",
    "# 10 for organ, 12 for muscle and 256 for spinal cord\n",
    "\n",
    "for i in range(Size_X):\n",
    "    for j in range(Size_Y):\n",
    "        for k in range(Size_Z):\n",
    "\n",
    "            pixel = slicer_data[i,j,k]\n",
    "            \n",
    "            if  pixel in bone_list:\n",
    "                img_new_LE[i,j,k] = 3\n",
    "\n",
    "            elif pixel in soft_tissue_list:\n",
    "                img_new_LE[i,j,k] = 2\n",
    "            \n",
    "            elif pixel in sinus_list:\n",
    "                img_new_LE[i,j,k] = 15\n",
    "\n",
    "            # For lungs - internal air\n",
    "            elif pixel in lungs:\n",
    "                img_new_LE[i,j,k] = 7\n",
    "            # For trachea - internal air\n",
    "            elif pixel in trachea:\n",
    "                img_new_LE[i,j,k] = 8\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, slicer_img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7460182",
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.save(new_nifti_img, \"D:/UNF_data/2024_08_23/slicer_work/slicer_to_converter_segs_raw_better.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6f9a7",
   "metadata": {},
   "source": [
    "# Working grouping samseg labels </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3ec42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samseg_brain_list = [2,3,4,5,7,8,10,11,12,13,14,15,16,17,18,24,26,28,30,31,41,42,43,44,46,47,49,50,51,52,53,54,58,60,62,63,72,77,80,85] #16 is the brainstem\n",
    "samseg_skull_list = [165]\n",
    "\n",
    "Size_X=(samseg_data.shape)[0]\n",
    "Size_Y=(samseg_data.shape)[1]\n",
    "Size_Z=(samseg_data.shape)[2]\n",
    "\n",
    "img_new_LE = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(samseg_data[:,0,0])):\n",
    "    for j in range( len(samseg_data[0,:,0])):\n",
    "        for k in range( len(samseg_data[0,0,:])):\n",
    "\n",
    "            pixel = samseg_data[i,j,k]\n",
    "            if pixel in samseg_brain_list:\n",
    "                img_new_LE[i,j,k] = 23\n",
    "            if pixel in samseg_skull_list:\n",
    "                img_new_LE[i,j,k] = 25\n",
    "\n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, samseg_img.affine)\n",
    "nib.save(new_nifti_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/grouped_samseg_labels.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcabe1",
   "metadata": {},
   "source": [
    "### Now to add the skull and brain segmentations after correction of the skull - smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246a1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to load the new segs and the segmentation file where we want to add it\n",
    "new_samsegs_img = nib.load(\"C:/Users/User/msc_project/sus-optimization/data/crop_ismrm/corrected_crop_grouped_samseg_labels.nii.gz\")\n",
    "new_samsegs_data = np.array(new_samsegs_img.get_fdata())\n",
    "segmentations_to_add_img = nib.load(\"C:/Users/User/msc_project/sus-optimization/data/crop_ismrm/db0_030_segmentations_cropped_ISRMRM.nii.gz\")\n",
    "segmentations_to_add_data = np.array(segmentations_to_add_img.get_fdata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0095398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know that they are in the same coordinates we can use same index\n",
    "Size_X=(segmentations_to_add_data.shape)[0]\n",
    "Size_Y=(segmentations_to_add_data.shape)[1]\n",
    "Size_Z=(segmentations_to_add_data.shape)[2]\n",
    "\n",
    "new_segmentation_data = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(segmentations_to_add_data[:,0,0])):\n",
    "    for j in range( len(segmentations_to_add_data[0,:,0])):\n",
    "        for k in range( len(segmentations_to_add_data[0,0,:])):\n",
    "\n",
    "            pixel_samseg = new_samsegs_data[i,j,k]\n",
    "            pixel_body_segs = segmentations_to_add_data[i,j,k]\n",
    "\n",
    "            if pixel_samseg == 1 or pixel_samseg == 2 or pixel_samseg == 23 or pixel_samseg == 25:\n",
    "                # This means there is something in samseg seg\n",
    "                if pixel_body_segs == 2:\n",
    "                    if pixel_samseg == 1: #brain\n",
    "                        new_segmentation_data[i,j,k] = 23\n",
    "                    if pixel_samseg == 2:\n",
    "                        new_segmentation_data[i,j,k] = 25\n",
    "                if pixel_body_segs == 15:\n",
    "                    new_segmentation_data[i,j,k] = 15\n",
    "                if pixel_body_segs == 8:\n",
    "                    new_segmentation_data[i,j,k] = 8\n",
    "\n",
    "            else:\n",
    "                new_segmentation_data[i,j,k] = pixel_body_segs\n",
    "\n",
    "new_seg_img = nib.Nifti1Image(new_segmentation_data, segmentations_to_add_img.affine)\n",
    "nib.save(new_seg_img, \"C:/Users/User/msc_project/sus-optimization/data/crop_ismrm/complete_crop_db0_030_segs.nii.gz\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24992058",
   "metadata": {},
   "source": [
    "### Converting samseg labelmap to tissue to MR converter dicitonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68180f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samseg_img = nib.load(\"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/final_db0_030_sementations_samseg.nii.gz\")\n",
    "final_samseg_data = final_samseg_img.get_fdata()\n",
    "\n",
    "Size_X=(final_samseg_data.shape)[0]\n",
    "Size_Y=(final_samseg_data.shape)[1]\n",
    "Size_Z=(final_samseg_data.shape)[2]\n",
    "\n",
    "final_segmentations_converter = np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(final_samseg_data[:,0,0])):\n",
    "    for j in range( len(final_samseg_data[0,:,0])):\n",
    "        for k in range( len(final_samseg_data[0,0,:])):\n",
    "\n",
    "            pixel = final_samseg_data[i,j,k]\n",
    "            final_pixel = final_segmentations_converter[i,j,k]\n",
    "\n",
    "            if pixel == 1: # Fat label\n",
    "                final_segmentations_converter[i,j,k] = 2\n",
    "            if pixel == 2 or pixel == 6: # Bone from spine and skull respectively\n",
    "                final_segmentations_converter[i,j,k] = 3\n",
    "            if pixel == 3: # Lungs\n",
    "                final_segmentations_converter[i,j,k] = 7\n",
    "            if pixel == 4: # Sinus\n",
    "                final_segmentations_converter[i,j,k] = 15\n",
    "            if pixel == 5: # Brain\n",
    "                final_segmentations_converter[i,j,k] = 23\n",
    "            if pixel == 7: # Trachea\n",
    "                final_segmentations_converter[i,j,k] = 8\n",
    "\n",
    "final_segmentations_converter_img =  nib.Nifti1Image(final_segmentations_converter, final_samseg_img.affine)\n",
    "nib.save(final_segmentations_converter_img, \"C:/Users/User/msc_project/Image-processing-strategies/mask_control/projects/db0_030/final_db0_030_sementations_converter.nii.gz\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0b766",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9d6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This to force a value to be the only one\n",
    "# This happens when we multiply by a negative value with sct\n",
    "\n",
    "value = 324\n",
    "\n",
    "Size_X=(image_gt2.shape)[0]\n",
    "Size_Y=(image_gt2.shape)[1]\n",
    "Size_Z=(image_gt2.shape)[2]\n",
    "img_new_LE=np.zeros((Size_X,Size_Y,Size_Z))\n",
    "\n",
    "for i in range(len(image_gt2[:,0,0])):\n",
    "    for j in range( len(image_gt2[0,:,0])):\n",
    "        for z in range( len(image_gt2[0,0,:])):\n",
    "            if image_gt2[i,j,z] == 200 or image_gt2[i,j,z] == 201:\n",
    "                img_new_LE[i,j,z] = 1\n",
    "            else:\n",
    "              img_new_LE[i,j,z] = 0\n",
    "                \n",
    "new_nifti_img = nib.Nifti1Image(img_new_LE, samseg_img.affine)\n",
    "nib.save(new_nifti_img, \"D:/UNF_data/2024_08_23/test_model_T1w/MP2RAGE/spine_output/only_sc_t1w.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e4e72",
   "metadata": {},
   "source": [
    "*Special thank you to fellow Peruvian, researcher and friend N. Medina - Aix Marseille*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa1332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes when tresholding the initial anatomical image, the binarized has wholes on the body of the image.\n",
    "# So we need some way to fill this wholes automatically.\n",
    "\n",
    "def get_neighbors(volume, x, y, z):\n",
    "    neighbors = []\n",
    "    for i in range(-1, 2):\n",
    "        for j in range(-1, 2):\n",
    "            for k in range(-1, 2):\n",
    "                if i == 0 and j == 0 and k == 0:\n",
    "                    continue\n",
    "                xi, yj, zk = x + i, y + j, z + k\n",
    "                if 0 <= xi < volume.shape[0] and 0 <= yj < volume.shape[1] and 0 <= zk < volume.shape[2]:\n",
    "                    neighbors.append(volume[xi, yj, zk])\n",
    "    return neighbors\n",
    "\n",
    "def fill_holes(volume):\n",
    "    filled_volume = volume.copy()\n",
    "    for x in range(volume.shape[0]):\n",
    "        for y in range(volume.shape[1]):\n",
    "            for z in range(volume.shape[2]):\n",
    "                if volume[x, y, z] == 0:  # Assuming 0 is the \"hole\"\n",
    "                    neighbors = get_neighbors(volume, x, y, z)\n",
    "                    if sum(neighbors) > len(neighbors) // 2:  # Majority vote\n",
    "                        filled_volume[x, y, z] = 1\n",
    "    return filled_volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78be2c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 320, 320)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image to load and fill holes\n",
    "path_database = \"correc_thoracic_db0_028.nii.gz\"\n",
    "\n",
    "wholes_image = nib.load(path_database)  # labels_total_seg.nii.gz\n",
    "wholes_data = np.array(image_gt_data.get_fdata())\n",
    "wholes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8002163",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_vol = fill_holes(wholes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7439594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and checking if the wholes were filled correctly\n",
    "fn = \"filled_wholes\"\n",
    "file = \"thoracic_db0_028\"\n",
    "\n",
    "out_fn2 = fn + \"_\" + file + \".nii.gz\"\n",
    "filled_vol_nii = nib.Nifti1Image(filled_vol, affine = wholes_image.affine)\n",
    "nib.save(filled_vol_nii, out_fn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94478758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the labels from Total Segmentator to leave and empty space on the place of the mask\n",
    "\n",
    "# Load the segmentations\n",
    "\n",
    "segmentation_path = \"D:/UNF_data/07_08_2024/T1w/thoracic_volume/thoracic_labels_bin.nii.gz\"\n",
    "\n",
    "segms = nib.load(segmentation_path)\n",
    "segmentation_data = segms.get_fdata()\n",
    "\n",
    "dimensions = np.array(segmentation_data.shape)\n",
    "\n",
    "final_filled_vol = filled_vol.copy()\n",
    "for i in range(dimensions[0]):\n",
    "    for j in range(dimensions[1]):\n",
    "        for k in range(dimensions[2]):\n",
    "            pixel = segmentation_data[i,j,k]\n",
    "            if pixel == 1:\n",
    "                final_filled_vol[i,j,k] = 0\n",
    "\n",
    "out_fn3 = \"final_\" + fn + \"_\" + file + \".nii.gz\"\n",
    "\n",
    "final_nii = nib.Nifti1Image(final_filled_vol, affine = segms.affine)\n",
    "nib.save(final_nii, out_fn3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
